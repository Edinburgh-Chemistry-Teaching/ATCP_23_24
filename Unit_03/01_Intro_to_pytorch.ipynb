{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a72cab",
   "metadata": {},
   "source": [
    "# Getting Started with PyTorch\n",
    "    \n",
    "<a rel=\"license\" href=\"https://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Licence\" style=\"width=50\" src=\"https://licensebuttons.net/l/by/4.0/88x31.png\" title='This work is licensed under a Creative Commons Attribution 4.0 International License.' align=\"right\"/></a>\n",
    "\n",
    "**Authors**: \n",
    "- Dr Antonia Mey (antonia.mey@ed.ac.uk)\n",
    "- Katerina Karoni\n",
    "\n",
    "Some content was also adapted from the [scikit-learn](https://scikit-learn.org/stable/auto_examples/index.html) and [pytorch](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html) documentation and examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96047d0",
   "metadata": {},
   "source": [
    "**Learning Objectives**:\n",
    "* Getting familiar with some PyTorch basics:\n",
    "    * What is a tensor\n",
    "    * How to build a dataset\n",
    "    * How to build a neural network\n",
    "    * Choosing an optimiser\n",
    "    * Testing and training a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33497e6",
   "metadata": {},
   "source": [
    "**Jupyter cheat sheet**:\n",
    "* to run the currently highlighted cell, hold <kbd>&#x21E7; Shift</kbd> and press <kbd>&#x23ce; Enter</kbd>;\n",
    "* to get help for a specific function, place the cursor within the function's brackets, hold <kbd>&#x21E7; Shift</kbd>, and press <kbd>&#x21E5; Tab</kbd>;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e97feb8",
   "metadata": {},
   "source": [
    "## PyTorch Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba58247d",
   "metadata": {},
   "source": [
    "PyTorch is a Python framework that provides two high-level features:\n",
    "\n",
    "    Tensor computation (like NumPy) with strong GPU acceleration\n",
    "    Deep neural networks built on a autograd system\n",
    "\n",
    "You can reuse your favorite Python packages such as NumPy to extend PyTorch when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5215a1b",
   "metadata": {},
   "source": [
    "**<h2>Pytorch Installation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0317ce5",
   "metadata": {},
   "source": [
    "So far we have only used scikit-learn. Today we will be using PyTorch. If you wanted to install it locally then use the command below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46f601b",
   "metadata": {},
   "source": [
    "```conda install pytorch torchvision -c pytorch```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff5d68",
   "metadata": {},
   "source": [
    "For more information on the installation please check out: https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22931231",
   "metadata": {},
   "source": [
    "⚠️ If you want to make use of the GPUs on Colab we should use the Colab version of today's notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cb3391",
   "metadata": {},
   "source": [
    "## Google Colab package installs\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "The following cell install necessary packages and downloads data if you are running this tutorial using Google Colab.<br>\n",
    "<b><i>Run this cell only if you are using Google Colab!</i></b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98976c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "!if [ -n \"$COLAB_RELEASE_TAG\" ]; then pip install condacolab; fi\n",
    "import condacolab\n",
    "condacolab.install()\n",
    "\n",
    "import condacolab\n",
    "condacolab.check()\n",
    "!mamba install -c conda-forge scikit-learn\n",
    "!mamba install pytorch torchvision torchinfo -c pytorch\n",
    "\n",
    "# copy over data repository\n",
    "!if [ -n \"$COLAB_RELEASE_TAG\" ]; then git clone https://github.com/Edinburgh-Chemistry-Teaching/ML-for-Chemistry; fi\n",
    "!if [ -n \"$COLAB_RELEASE_TAG\" ]; then cp -r ML-for-Chemistry/data .; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc9bed8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cf7db7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53553e38",
   "metadata": {},
   "source": [
    "**<h2>Tensors**\n",
    "    \n",
    "A PyTorch Tensor is basically the same as a numpy array: it does not know anything about deep learning or computational graphs or gradients, and is just a generic n-dimensional array to be used for arbitrary numeric computation.\n",
    "\n",
    "The biggest difference between a numpy array and a PyTorch Tensor is that a PyTorch Tensor can run on either **CPU** or **GPU**. To run operations on the GPU, just cast the Tensor to a `cuda datatype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "56430451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "Size of x = torch.Size([2, 3])\n",
      "Data type of x = torch.float64\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "\n",
    "print(f'x = {x}')\n",
    "\n",
    "print(f'Size of x = {x.size()}') # np.shape(x) also works\n",
    "\n",
    "print(f'Data type of x = {x.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "56ea112e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float32)\n",
      "Data type of y = torch.float32\n"
     ]
    }
   ],
   "source": [
    "# we can also specify data type\n",
    "\n",
    "y = torch.zeros(2,3,dtype=torch.float32) \n",
    "\n",
    "print(f'y = {y}')\n",
    "\n",
    "print(f'Data type of y = {y.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d271cf66",
   "metadata": {},
   "source": [
    "**Casting tensor x as cuda datatype if cuda available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "06c07389",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42b80cf",
   "metadata": {},
   "source": [
    "Attention: ```x.to(device)``` will not cast ```x```as cuda datatype - we need\n",
    "```x = x.to(device)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "100e3d99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "y = x.to(device) # or x = x.cuda() for GPU\n",
    "print(x.is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee1ebc0",
   "metadata": {},
   "source": [
    "Note: For tensors ```x.to(device)```, as mentioned does not move ```x``` to cuda and we need to write ```x = x.to(device)``` instead.\n",
    "\n",
    "However, for neural networks, ```net.to(device)``` and\n",
    "```net = net.to(device)``` are equivalent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f5254",
   "metadata": {},
   "source": [
    "**Tensor Data types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad495d27",
   "metadata": {},
   "source": [
    "```DoubleTensor``` is ```64-bit``` floating point and ```FloatTensor``` is ```32-bit``` floating point tensor. So a ```FloatTensor``` uses half of the memory as a same tensor-size ```DoubleTensor``` uses. Also GPU and CPU computations with lower precision are much faster.  However, if high precision is needed, go for ```DoubleTensor``` . So Pytorch leaves it to user to choose which one to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd5458a",
   "metadata": {},
   "source": [
    "Set default tensor type for your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "009acf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type('torch.FloatTensor')    # 32 bits\n",
    "#or\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')    # 64 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1576f635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2,3) \n",
    "print(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037decaa",
   "metadata": {},
   "source": [
    "## Show case: Components needed to run a classification with a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c4bfe2",
   "metadata": {},
   "source": [
    "We will now present an example where we train a fully-connected neural network on a popular benchmark dataset: MNIST handwritten digits.\n",
    "\n",
    "The MNIST had-written digits dataset consists of 60,000 training examples and 10,000 test examples. Each example comprises a 8×8 image and an associated label from one of 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b37a757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn import datasets\n",
    "from   torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a413d6d9",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557735be",
   "metadata": {},
   "source": [
    "The ```torchvision``` library consists of popular datasets, model architectures, and common image transformations for computer vision. Since we have been using `scikit learn` we will use this data set in the example here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "059ffd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f7020ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Training: %i\" % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "12249f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "06ae0d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a torch tensor:\n",
    "\n",
    "x = torch.Tensor(digits['data']) # data\n",
    "y = torch.Tensor(digits['target']) # labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "11d47053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2.,  ..., 8., 9., 8.])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ecb35",
   "metadata": {},
   "source": [
    "**<h3> Dataloader class**\n",
    "    \n",
    "https://pytorch.org/docs/stable/data.html#map-style-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f955aa",
   "metadata": {},
   "source": [
    "At the heart of ```PyTorch``` data loading utility is the ```torch.utils.data.DataLoader``` class. It represents a Python iterable over a dataset\n",
    "\n",
    "```python\n",
    "DataLoader(dataset, batch_size=1, shuffle=False, \n",
    "           sampler=None,batch_sampler=None, num_workers=0,\n",
    "           collate_fn=None,pin_memory=False, drop_last=False, \n",
    "           timeout=0, worker_init_fn=None, *, prefetch_factor=2,\n",
    "           persistent_workers=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d96636f",
   "metadata": {},
   "source": [
    "The most important argument of ```DataLoader``` constructor is ```dataset```, which indicates a dataset object to load data from. PyTorch supports two different types of datasets:\n",
    "\n",
    "- Map style datasets: Datasets that implement the ```__getitem__()``` and ```__len__()``` methods and are maps from keys to data samples.\n",
    "\n",
    "- Iterable style datasets: When reading from a stream of data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "33f3f386",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Split the train data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60779ddb",
   "metadata": {},
   "source": [
    "Let's check that our data is of torch data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c3d9dcfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9830a69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next the data needs to be wrapped into a Tensor dataset and then we can use a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "efeccfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap your data in TensorDataset\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Create the dataloaders\n",
    "batch_size = 128\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "47acbdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape train and test images from 8x8 to 1x64\n",
    "for i,data in enumerate(dataloader_train):\n",
    "    xtrain = data[0].view(-1,64)       # torch.Tensor.view() is equivalent to reshape\n",
    "    ytrain = data[1].type(torch.LongTensor)                    # train labels\n",
    "\n",
    "for i,data in enumerate(dataloader_test):      \n",
    "    xtest = data[0].view(-1,64)     # test images, The size -1 is inferred from other dimensions\n",
    "    ytest = data[1].type(torch.LongTensor)                            # test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "45b654ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_mnist_train       = TensorDataset(xtrain, ytrain)\n",
    "flat_dataloader_train  =  DataLoader(flat_mnist_train, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "af0faaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([125, 64])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c42b6143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fee349",
   "metadata": {},
   "source": [
    "## Defining the Neural network\n",
    "\n",
    "This is a 4 layer linear fully connected network. This is just an example\n",
    "Notice how the forward function is defined and how it uses the ReLu activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5decffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "555148b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_net(nn.Module):    # this class inherits from nn.Module\n",
    "    def __init__(self):\n",
    "        super(Neural_net, self).__init__() #this calls the constructor of the parent class nn.Module\n",
    "        \n",
    "        # define network layers\n",
    "        self.fc1 = nn.Linear(64, 20)   # nn.Linear is a class for linear layers (16,12) are the constructor arguments\n",
    "        self.fc2 = nn.Linear(20, 20)\n",
    "        self.fc3 = nn.Linear(20, 20)\n",
    "        self.fc4 = nn.Linear(20, 10)\n",
    "        torch.manual_seed(4)           # generating numbers changes the state of the random number generator.\n",
    "                                       # we thus have to set the seed back to 2  \n",
    "            \n",
    "        # Notice the RELU activation function below\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))  # \n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6f452c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Neural_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8644d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_accuracy(output,y):\n",
    "    '''If np.argmax(out,axis=1)-y is non-zero, i.e. label y is 9 and prediction is 5 then \n",
    "       diff is incremented by 1, i.e. every time there is a mismatch between prediction and label.\n",
    "       The ratio diff/np.size(y) gives us the ratio of false predictions over the total number of datapoints.\n",
    "       One minus that gives the model accuracy.\n",
    "       '''\n",
    "    # we can't call numpy() on Tensors that requires grad. So, in order to compute diff (see below)\n",
    "    # we need to use tensor.detach().numpy()\n",
    "    output = output.cpu().detach().numpy()    # no need for the .cpu() here as we are working with cpu tensors\n",
    "    y      = y.cpu().detach().numpy()\n",
    "    diff   = np.count_nonzero(np.argmax(output,axis=1)-y) # np.argmax returns the index/indices of max value(s)\n",
    "                                                        # along specified axis\n",
    "    return (1-(diff/np.size(y)))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039aca31",
   "metadata": {},
   "source": [
    "## Important Model and training parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1425302",
   "metadata": {},
   "source": [
    "### The optimiser\n",
    "\n",
    "The optimiser module gives access to a large number of standard optimisers that try and help minimise the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8bd67598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd2a611",
   "metadata": {},
   "source": [
    "There are different options. Take a look at adam and sgd (stocastic gradient descent), both are very common choices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cdd7ca",
   "metadata": {},
   "source": [
    "### The loss\n",
    "\n",
    "Typically for a classification problem one would use a cross entrop loss, the [torch documentation](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) has some more details on this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff51795",
   "metadata": {},
   "source": [
    "Cross entropy loss is generally defined for two probability distributions $p$ and $q$ as:\n",
    "\n",
    "$$H(p,q) =  –\\sum_{x \\in \\mathcal{X}} p(x)  \\log(q(x))$$\n",
    "\n",
    "For binary classification\n",
    "\n",
    "$$\\mathrm{loss}=−(y \\log(p)+(1−y) \\log(1−p))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b4de0",
   "metadata": {},
   "source": [
    "### The learning rate \n",
    "This is a parameter you set in your optimiser an you can play around with different values for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bda2b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6aedfb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0/100, accuracy train 15.20 %, loss train, 2.35421, accuracy test 11.54 %, loss test, 2.28370\n",
      "epoch 1/100, accuracy train 12.00 %, loss train, 2.28578, accuracy test 12.50 %, loss test, 2.24444\n",
      "epoch 2/100, accuracy train 12.00 %, loss train, 2.23142, accuracy test 16.35 %, loss test, 2.21314\n",
      "epoch 3/100, accuracy train 22.40 %, loss train, 2.18321, accuracy test 17.31 %, loss test, 2.18146\n",
      "epoch 4/100, accuracy train 24.80 %, loss train, 2.13286, accuracy test 17.31 %, loss test, 2.14936\n",
      "epoch 5/100, accuracy train 25.60 %, loss train, 2.07737, accuracy test 17.31 %, loss test, 2.11977\n",
      "epoch 6/100, accuracy train 25.60 %, loss train, 2.01628, accuracy test 17.31 %, loss test, 2.08212\n",
      "epoch 7/100, accuracy train 28.00 %, loss train, 1.95280, accuracy test 19.23 %, loss test, 2.02651\n",
      "epoch 8/100, accuracy train 28.80 %, loss train, 1.88514, accuracy test 20.19 %, loss test, 1.95977\n",
      "epoch 9/100, accuracy train 28.00 %, loss train, 1.81541, accuracy test 20.19 %, loss test, 1.88947\n",
      "epoch 10/100, accuracy train 29.60 %, loss train, 1.73673, accuracy test 24.04 %, loss test, 1.81128\n",
      "epoch 11/100, accuracy train 33.60 %, loss train, 1.65062, accuracy test 31.73 %, loss test, 1.72801\n",
      "epoch 12/100, accuracy train 42.40 %, loss train, 1.56066, accuracy test 40.38 %, loss test, 1.63313\n",
      "epoch 13/100, accuracy train 48.80 %, loss train, 1.46544, accuracy test 50.00 %, loss test, 1.52602\n",
      "epoch 14/100, accuracy train 57.60 %, loss train, 1.36559, accuracy test 56.73 %, loss test, 1.41713\n",
      "epoch 15/100, accuracy train 63.20 %, loss train, 1.26029, accuracy test 63.46 %, loss test, 1.30525\n",
      "epoch 16/100, accuracy train 71.20 %, loss train, 1.15278, accuracy test 62.50 %, loss test, 1.19025\n",
      "epoch 17/100, accuracy train 71.20 %, loss train, 1.04835, accuracy test 68.27 %, loss test, 1.06336\n",
      "epoch 18/100, accuracy train 78.40 %, loss train, 0.95153, accuracy test 71.15 %, loss test, 0.95055\n",
      "epoch 19/100, accuracy train 77.60 %, loss train, 0.86043, accuracy test 72.12 %, loss test, 0.83276\n",
      "epoch 20/100, accuracy train 80.00 %, loss train, 0.76418, accuracy test 75.96 %, loss test, 0.73245\n",
      "epoch 21/100, accuracy train 83.20 %, loss train, 0.66618, accuracy test 76.92 %, loss test, 0.65767\n",
      "epoch 22/100, accuracy train 86.40 %, loss train, 0.57645, accuracy test 83.65 %, loss test, 0.59604\n",
      "epoch 23/100, accuracy train 88.00 %, loss train, 0.50212, accuracy test 84.62 %, loss test, 0.54594\n",
      "epoch 24/100, accuracy train 87.20 %, loss train, 0.44169, accuracy test 87.50 %, loss test, 0.51530\n",
      "epoch 25/100, accuracy train 86.40 %, loss train, 0.38832, accuracy test 84.62 %, loss test, 0.48493\n",
      "epoch 26/100, accuracy train 92.00 %, loss train, 0.33959, accuracy test 87.50 %, loss test, 0.44074\n",
      "epoch 27/100, accuracy train 92.80 %, loss train, 0.29419, accuracy test 89.42 %, loss test, 0.39365\n",
      "epoch 28/100, accuracy train 94.40 %, loss train, 0.25609, accuracy test 89.42 %, loss test, 0.36850\n",
      "epoch 29/100, accuracy train 94.40 %, loss train, 0.22383, accuracy test 91.35 %, loss test, 0.34406\n",
      "epoch 30/100, accuracy train 96.80 %, loss train, 0.19623, accuracy test 93.27 %, loss test, 0.32505\n",
      "epoch 31/100, accuracy train 95.20 %, loss train, 0.17210, accuracy test 93.27 %, loss test, 0.32766\n",
      "epoch 32/100, accuracy train 96.80 %, loss train, 0.14866, accuracy test 92.31 %, loss test, 0.33285\n",
      "epoch 33/100, accuracy train 96.80 %, loss train, 0.12771, accuracy test 92.31 %, loss test, 0.31709\n",
      "epoch 34/100, accuracy train 98.40 %, loss train, 0.10982, accuracy test 93.27 %, loss test, 0.30208\n",
      "epoch 35/100, accuracy train 100.00 %, loss train, 0.09519, accuracy test 94.23 %, loss test, 0.29891\n",
      "epoch 36/100, accuracy train 100.00 %, loss train, 0.08154, accuracy test 93.27 %, loss test, 0.30398\n",
      "epoch 37/100, accuracy train 100.00 %, loss train, 0.06972, accuracy test 94.23 %, loss test, 0.29952\n",
      "epoch 38/100, accuracy train 100.00 %, loss train, 0.05904, accuracy test 94.23 %, loss test, 0.29082\n",
      "epoch 39/100, accuracy train 100.00 %, loss train, 0.04936, accuracy test 94.23 %, loss test, 0.28346\n",
      "epoch 40/100, accuracy train 100.00 %, loss train, 0.04151, accuracy test 94.23 %, loss test, 0.27801\n",
      "epoch 41/100, accuracy train 100.00 %, loss train, 0.03480, accuracy test 94.23 %, loss test, 0.27633\n",
      "epoch 42/100, accuracy train 100.00 %, loss train, 0.02954, accuracy test 94.23 %, loss test, 0.28190\n",
      "epoch 43/100, accuracy train 100.00 %, loss train, 0.02544, accuracy test 94.23 %, loss test, 0.28506\n",
      "epoch 44/100, accuracy train 100.00 %, loss train, 0.02157, accuracy test 94.23 %, loss test, 0.28472\n",
      "epoch 45/100, accuracy train 100.00 %, loss train, 0.01827, accuracy test 94.23 %, loss test, 0.28445\n",
      "epoch 46/100, accuracy train 100.00 %, loss train, 0.01544, accuracy test 94.23 %, loss test, 0.28754\n",
      "epoch 47/100, accuracy train 100.00 %, loss train, 0.01299, accuracy test 94.23 %, loss test, 0.29553\n",
      "epoch 48/100, accuracy train 100.00 %, loss train, 0.01099, accuracy test 94.23 %, loss test, 0.30567\n",
      "epoch 49/100, accuracy train 100.00 %, loss train, 0.00946, accuracy test 94.23 %, loss test, 0.31410\n",
      "epoch 50/100, accuracy train 100.00 %, loss train, 0.00821, accuracy test 94.23 %, loss test, 0.31814\n",
      "epoch 51/100, accuracy train 100.00 %, loss train, 0.00714, accuracy test 94.23 %, loss test, 0.31771\n",
      "epoch 52/100, accuracy train 100.00 %, loss train, 0.00622, accuracy test 95.19 %, loss test, 0.31578\n",
      "epoch 53/100, accuracy train 100.00 %, loss train, 0.00544, accuracy test 95.19 %, loss test, 0.31368\n",
      "epoch 54/100, accuracy train 100.00 %, loss train, 0.00480, accuracy test 95.19 %, loss test, 0.31239\n",
      "epoch 55/100, accuracy train 100.00 %, loss train, 0.00426, accuracy test 95.19 %, loss test, 0.31216\n",
      "epoch 56/100, accuracy train 100.00 %, loss train, 0.00382, accuracy test 95.19 %, loss test, 0.31330\n",
      "epoch 57/100, accuracy train 100.00 %, loss train, 0.00344, accuracy test 95.19 %, loss test, 0.31514\n",
      "epoch 58/100, accuracy train 100.00 %, loss train, 0.00312, accuracy test 95.19 %, loss test, 0.31698\n",
      "epoch 59/100, accuracy train 100.00 %, loss train, 0.00285, accuracy test 95.19 %, loss test, 0.31886\n",
      "epoch 60/100, accuracy train 100.00 %, loss train, 0.00261, accuracy test 95.19 %, loss test, 0.32030\n",
      "epoch 61/100, accuracy train 100.00 %, loss train, 0.00241, accuracy test 95.19 %, loss test, 0.32115\n",
      "epoch 62/100, accuracy train 100.00 %, loss train, 0.00224, accuracy test 95.19 %, loss test, 0.32148\n",
      "epoch 63/100, accuracy train 100.00 %, loss train, 0.00208, accuracy test 95.19 %, loss test, 0.32130\n",
      "epoch 64/100, accuracy train 100.00 %, loss train, 0.00195, accuracy test 95.19 %, loss test, 0.32082\n",
      "epoch 65/100, accuracy train 100.00 %, loss train, 0.00183, accuracy test 95.19 %, loss test, 0.32008\n",
      "epoch 66/100, accuracy train 100.00 %, loss train, 0.00172, accuracy test 95.19 %, loss test, 0.31916\n",
      "epoch 67/100, accuracy train 100.00 %, loss train, 0.00162, accuracy test 95.19 %, loss test, 0.31797\n",
      "epoch 68/100, accuracy train 100.00 %, loss train, 0.00153, accuracy test 95.19 %, loss test, 0.31704\n",
      "epoch 69/100, accuracy train 100.00 %, loss train, 0.00146, accuracy test 95.19 %, loss test, 0.31634\n",
      "epoch 70/100, accuracy train 100.00 %, loss train, 0.00139, accuracy test 95.19 %, loss test, 0.31594\n",
      "epoch 71/100, accuracy train 100.00 %, loss train, 0.00132, accuracy test 95.19 %, loss test, 0.31583\n",
      "epoch 72/100, accuracy train 100.00 %, loss train, 0.00126, accuracy test 95.19 %, loss test, 0.31593\n",
      "epoch 73/100, accuracy train 100.00 %, loss train, 0.00121, accuracy test 95.19 %, loss test, 0.31619\n",
      "epoch 74/100, accuracy train 100.00 %, loss train, 0.00115, accuracy test 95.19 %, loss test, 0.31653\n",
      "epoch 75/100, accuracy train 100.00 %, loss train, 0.00111, accuracy test 95.19 %, loss test, 0.31689\n",
      "epoch 76/100, accuracy train 100.00 %, loss train, 0.00106, accuracy test 95.19 %, loss test, 0.31724\n",
      "epoch 77/100, accuracy train 100.00 %, loss train, 0.00103, accuracy test 95.19 %, loss test, 0.31737\n",
      "epoch 78/100, accuracy train 100.00 %, loss train, 0.00099, accuracy test 95.19 %, loss test, 0.31728\n",
      "epoch 79/100, accuracy train 100.00 %, loss train, 0.00096, accuracy test 95.19 %, loss test, 0.31681\n",
      "epoch 80/100, accuracy train 100.00 %, loss train, 0.00093, accuracy test 95.19 %, loss test, 0.31603\n",
      "epoch 81/100, accuracy train 100.00 %, loss train, 0.00090, accuracy test 95.19 %, loss test, 0.31498\n",
      "epoch 82/100, accuracy train 100.00 %, loss train, 0.00088, accuracy test 95.19 %, loss test, 0.31375\n",
      "epoch 83/100, accuracy train 100.00 %, loss train, 0.00085, accuracy test 95.19 %, loss test, 0.31243\n",
      "epoch 84/100, accuracy train 100.00 %, loss train, 0.00083, accuracy test 95.19 %, loss test, 0.31120\n",
      "epoch 85/100, accuracy train 100.00 %, loss train, 0.00081, accuracy test 95.19 %, loss test, 0.31013\n",
      "epoch 86/100, accuracy train 100.00 %, loss train, 0.00079, accuracy test 95.19 %, loss test, 0.30922\n",
      "epoch 87/100, accuracy train 100.00 %, loss train, 0.00078, accuracy test 95.19 %, loss test, 0.30852\n",
      "epoch 88/100, accuracy train 100.00 %, loss train, 0.00076, accuracy test 95.19 %, loss test, 0.30788\n",
      "epoch 89/100, accuracy train 100.00 %, loss train, 0.00075, accuracy test 95.19 %, loss test, 0.30734\n",
      "epoch 90/100, accuracy train 100.00 %, loss train, 0.00073, accuracy test 95.19 %, loss test, 0.30692\n",
      "epoch 91/100, accuracy train 100.00 %, loss train, 0.00072, accuracy test 95.19 %, loss test, 0.30663\n",
      "epoch 92/100, accuracy train 100.00 %, loss train, 0.00070, accuracy test 95.19 %, loss test, 0.30648\n",
      "epoch 93/100, accuracy train 100.00 %, loss train, 0.00069, accuracy test 95.19 %, loss test, 0.30645\n",
      "epoch 94/100, accuracy train 100.00 %, loss train, 0.00068, accuracy test 95.19 %, loss test, 0.30650\n",
      "epoch 95/100, accuracy train 100.00 %, loss train, 0.00067, accuracy test 95.19 %, loss test, 0.30659\n",
      "epoch 96/100, accuracy train 100.00 %, loss train, 0.00066, accuracy test 95.19 %, loss test, 0.30682\n",
      "epoch 97/100, accuracy train 100.00 %, loss train, 0.00065, accuracy test 95.19 %, loss test, 0.30713\n",
      "epoch 98/100, accuracy train 100.00 %, loss train, 0.00064, accuracy test 95.19 %, loss test, 0.30736\n",
      "epoch 99/100, accuracy train 100.00 %, loss train, 0.00063, accuracy test 95.19 %, loss test, 0.30747\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "# The criterion we want to optimse\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Defining the optimiser\n",
    "# lr is the learnig rate\n",
    "optimizer = optim.Adam(net.parameters(), lr=5*10**-3)\n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "    for i,data in enumerate(flat_dataloader_train):\n",
    "        # Load in the training datapoints\n",
    "        x=data[0]                 \n",
    "        y=data[1]   \n",
    "        optimizer.zero_grad()\n",
    "        # The output of the current net\n",
    "        output = net(x)\n",
    "        loss = criterion(output,y) \n",
    "        loss.backward()\n",
    "        # Optimising one more step\n",
    "        optimizer.step()\n",
    "                   \n",
    "        if epoch % 1 == 0 and i==0:\n",
    "            # test the accuracy \n",
    "            acc        = class_accuracy(output,y)\n",
    "            outputtest = net(xtest)\n",
    "            loss_test  = criterion(outputtest,ytest)\n",
    "            acc_test   = class_accuracy(outputtest,ytest)\n",
    "            print(f'epoch {epoch}/{num_epochs}, accuracy train {acc:.2f} %, loss train, {loss.item():.5f}, accuracy test {acc_test:.2f} %, loss test, {loss_test.item():.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de2bc56",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Task:</b> Train the neural network using 100 epochs and plot the quantities printed to screen.  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116f7483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e23925b",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary> <mark> Solution: </mark> </summary>\n",
    "\n",
    "```Python\n",
    "# Let's reinisalise the network\n",
    "net = Neural_net()\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "# The criterion we want to optimse\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Defining the optimiser\n",
    "# lr is the learnig rate\n",
    "optimizer = optim.Adam(net.parameters(), lr=5*10**-3)\n",
    "\n",
    "# list where we want to store the training information\n",
    "info = []\n",
    "for epoch in range(num_epochs): \n",
    "    for i,data in enumerate(flat_dataloader_train):\n",
    "        # Load in the training datapoints\n",
    "        x=data[0]                 \n",
    "        y=data[1]   \n",
    "        optimizer.zero_grad()\n",
    "        # The output of the current net\n",
    "        output = net(x)\n",
    "        loss = criterion(output,y) \n",
    "        loss.backward()\n",
    "        # Optimising one more step\n",
    "        optimizer.step()\n",
    "                   \n",
    "        if epoch % 1 == 0 and i==0:\n",
    "            # test the accuracy\n",
    "            acc        = class_accuracy(output,y)\n",
    "            outputtest = net(xtest)\n",
    "            loss_test  = criterion(outputtest,ytest).detach().cpu().numpy()\n",
    "            acc_test   = class_accuracy(outputtest,ytest)\n",
    "            print(float(loss_test))\n",
    "            info.append([acc, float(loss_test),acc_test])\n",
    "            print(f'epoch {epoch}/{num_epochs}, accuracy train {acc:.2f} %, loss train, {loss.item():.5f}, accuracy test {acc_test:.2f} %, loss test, {loss_test.item():.5f}')\n",
    "info = np.array(info)\n",
    "epochs = np.linspace(0,num_epochs,len(info))\n",
    "plt.plot(epochs, info[:,0], label='accuracy')\n",
    "plt.plot(epochs, info[:,1], label='loss_test')\n",
    "plt.plot(epochs, info[:,2], label='accuracy test')\n",
    "plt.legend()\n",
    "```\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9549c91",
   "metadata": {},
   "source": [
    "## END\n",
    "------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
