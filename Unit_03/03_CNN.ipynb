{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e5fc802-a846-4d8e-a8a9-7cfe0583e9e4",
   "metadata": {},
   "source": [
    "## 4. Extra Topic: Convolutional Neural Networks\n",
    "\n",
    "We define a new Deep Learning variant called **1D Convolutional Neural Network (CNN)** below.\n",
    "CNN is a type of deep learning model that is typically used for image and signal processing tasks. \n",
    "\n",
    "In this code, the model takes a 1D input signal of length 1024 and performs a series of convolution, pooling and fully connected operations to classify the signal into one of two classes. The `conv1` and `conv2` layers are 1D convolutional layers that apply filters to the input signal to extract features. The `pool1` and `pool2` layers are max-pooling layers that down-sample the input signal. The `fc1` and `fc2` layers are fully connected layers that perform classification based on the extracted features. The `softmax` activation is applied to the output to produce probabilities for each class. This gives us the classification into soluble and insoluble molecules. \n",
    "\n",
    "The steps are similar to DNN model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2092965-8296-477f-b8d8-cd229d979b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the 1D CNN model\n",
    "class CNN1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1D, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(32 * 256, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "        self.softmax = nn.Softmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 1, 1024)\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.reshape(-1, 32 * 256)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68e4253-ab9d-4055-8570-1eb6d2090703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model_cnn = CNN1D()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c85cb1-4d9e-47e2-bce1-8229bdac9c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ecb25-c113-41e4-a365-28bc9c4e45e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the CNN model and keep track of validation loss\n",
    "train_loss1 = []\n",
    "val_loss1 = []\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_cnn(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "    train_loss1.append(avg_train_loss)\n",
    "    \n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            inputs, labels = data\n",
    "            outputs = model_cnn(inputs)\n",
    "            \n",
    "            val_batch_loss = criterion(outputs, labels.long())\n",
    "            val_running_loss += val_batch_loss.item()\n",
    "        \n",
    "    avg_val_loss = val_running_loss / len(valloader)\n",
    "    val_loss1.append(avg_val_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f36f9e6-0579-45b2-ab86-ceffcfedf930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation loss\n",
    "plt.plot(range(num_epochs), train_loss1, label='Training Loss')\n",
    "plt.plot(range(num_epochs), val_loss1, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9913cd1-81ea-4d72-bcd1-fc29e79fc7b7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Task 4a.</b> From the above plot, what do you think about the CNN model's learning over 50 epochs. Compare its performance with DNN. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1a809b-ec0f-49ce-9fa4-bacdb7fb736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on the test data\n",
    "correct = 0\n",
    "total = 0\n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        inputs, target = data\n",
    "        outputs = model_cnn(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1) # Get the class with the highest probability\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target.long()).sum().item() # Convert target to long and compare\n",
    "        predictions += predicted.tolist()\n",
    "        true_labels += target.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec7a3d5-5dbd-416d-8ff3-ea7447bd0f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = correct / total\n",
    "print(f'Accuracy of the network on the test data: {(100 * accuracy):.2f} %' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf53454-98b5-4217-9d47-73ac1d689901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "cf_matrix= confusion_matrix(true_labels, predictions)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f60be7-870c-4bd3-8956-0e73017da249",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Task 4b.</b> Is there a change in true positive, false positive and false negative rates as compared to the DNN model? </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a88a2d-0b5e-4ac2-8cc2-dadda96a1212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
